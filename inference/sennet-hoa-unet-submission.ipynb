{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61446,"databundleVersionId":6962461,"sourceType":"competition"},{"sourceId":4053053,"sourceType":"datasetVersion","datasetId":2398033},{"sourceId":8197420,"sourceType":"datasetVersion","datasetId":4855734},{"sourceId":8201617,"sourceType":"datasetVersion","datasetId":4858785},{"sourceId":8202936,"sourceType":"datasetVersion","datasetId":4859785},{"sourceId":8204223,"sourceType":"datasetVersion","datasetId":4860802},{"sourceId":8218751,"sourceType":"datasetVersion","datasetId":4871808},{"sourceId":126502507,"sourceType":"kernelVersion"},{"sourceId":153879438,"sourceType":"kernelVersion"}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai -q --no-index --find-links=../input/vesuvis-downloads\n!python -m pip install -q /kaggle/input/omegaconf222py3/omegaconf-2.2.2-py3-none-any.whl --no-index --find-links=/kaggle/input/omegaconf222py3/","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:09:46.434074Z","iopub.execute_input":"2024-04-28T16:09:46.434782Z","iopub.status.idle":"2024-04-28T16:10:12.871737Z","shell.execute_reply.started":"2024-04-28T16:09:46.434747Z","shell.execute_reply":"2024-04-28T16:10:12.870594Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom tqdm import tqdm\nfrom tqdm.contrib.concurrent import thread_map\nfrom tqdm.asyncio import tqdm as async_tqdm\nfrom monai.inferers import SlidingWindowInferer\nimport pytorch_lightning as pl\n\nimport torch\nimport os\nfrom typing import Union, Dict, Tuple\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:10:12.873961Z","iopub.execute_input":"2024-04-28T16:10:12.874284Z","iopub.status.idle":"2024-04-28T16:10:57.876509Z","shell.execute_reply.started":"2024-04-28T16:10:12.874252Z","shell.execute_reply":"2024-04-28T16:10:57.875672Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-28 16:10:47.710411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 16:10:47.710518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 16:10:47.852044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if TPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('Running on GPU')\nelse:\n    device = torch.device(\"cpu\")\n    print('Running on CPU')\n\n# Print the number of replicas\nprint(\"Number of replicas: \", torch.cuda.device_count() if torch.cuda.is_available() else 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:10:57.877619Z","iopub.execute_input":"2024-04-28T16:10:57.878263Z","iopub.status.idle":"2024-04-28T16:10:57.884514Z","shell.execute_reply.started":"2024-04-28T16:10:57.878234Z","shell.execute_reply":"2024-04-28T16:10:57.883509Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Running on GPU\nNumber of replicas:  1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **DataSet Preparation**","metadata":{}},{"cell_type":"code","source":"MAIN_PATH = '/kaggle/input/blood-vessel-segmentation'\nTEST_PATH = MAIN_PATH + '/test'\nVALIDATION = MAIN_PATH + '/train/kidney_1_dense'\nWEIGHTS_PATH = '/kaggle/input/unet-bdou-loss-weights/UNet_BoundaryDoULoss_size_1_512_bs32_hard/0/checkpoints/last.ckpt'\nINPUT_CHANNELS, OUTPUT_CHANNELS = 1,1","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:00.890277Z","iopub.execute_input":"2024-04-28T16:13:00.890536Z","iopub.status.idle":"2024-04-28T16:13:00.894944Z","shell.execute_reply.started":"2024-04-28T16:13:00.890514Z","shell.execute_reply":"2024-04-28T16:13:00.894076Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BuildDataset:\n    def __init__(self, dataset: str, is_test: bool = True):\n        self.ids = []\n        self.is_test = is_test\n\n        self.xmin, self.xmax = 0, 0\n\n        self.data_tensor = self.load_volume(dataset)\n        self.shape_orig = self.data_tensor.shape\n        \n    def normilize(self, image: np.ndarray) -> np.ndarray:\n        if image.dtype != np.half:\n            image = image.astype(np.half, copy=False)\n            \n        image -= self.xmin\n        image /= (self.xmax - self.xmin)\n        \n        np.clip(image, 0, 1, out=image)\n        return image\n    \n    @staticmethod\n    def norm_by_percentile(\n        volume: np.ndarray, low: float = 10, high: float = 99.8\n    ) -> Tuple:\n        xmin = np.percentile(volume, low)\n        xmax = np.max([np.percentile(volume, high), 1])\n        return int(xmin), int(xmax)\n\n    def load_volume(self, dataset: str) -> np.ndarray:\n        path = os.path.join(dataset, \"images\", \"*.tif\")\n        \n        dataset = sorted(glob(path)) if self.is_test else sorted(glob(path))[:192]\n\n        for p_img in tqdm(dataset):\n            path_ = p_img.split(os.path.sep)\n            slice_id, _ = os.path.splitext(path_[-1])\n            self.ids.append(f\"{path_[-3]}_{slice_id}\")\n\n        volume = None\n\n        for z, path in enumerate(tqdm(dataset)):\n            image = cv2.imread(path, cv2.IMREAD_ANYDEPTH).astype(np.half, copy=False)\n            \n            if volume is None:\n                volume = np.zeros((len(dataset), *image.shape[-2:]), dtype=np.float16)\n            volume[z, :, :] = image\n            \n        self.xmin, self.xmax = self.norm_by_percentile(volume)\n        return volume","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:01.909253Z","iopub.execute_input":"2024-04-28T16:13:01.909924Z","iopub.status.idle":"2024-04-28T16:13:01.922733Z","shell.execute_reply.started":"2024-04-28T16:13:01.909894Z","shell.execute_reply":"2024-04-28T16:13:01.921714Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n#Model architecture\nclass Conv2dBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3):\n        super(Conv2dBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding='same')\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        return x\n\nclass EncoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, pool_type='avg', normalization=True):\n        super(EncoderBlock, self).__init__()\n        self.conv_block = Conv2dBlock(in_channels, out_channels)\n        self.normalisation = normalization\n        if pool_type == 'max':\n            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        elif pool_type == 'avg':\n            self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x_conv = self.conv_block(x)\n        x = self.pool(x_conv)\n        \n        if self.normalisation:\n            x = self.batch_norm(x)\n            \n        x = self.dropout(x)\n        return x, x_conv\n\nclass Bottleneck(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(Bottleneck, self).__init__()\n        self.conv_block = Conv2dBlock(in_channels, out_channels)\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        return x\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, normalization=True):\n        super(DecoderBlock, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=2, padding=1, output_padding=1)\n        self.conv_block = Conv2dBlock(in_channels, out_channels, kernel_size)\n        self.normalisation = normalization\n        \n        self.batch_norm = nn.BatchNorm2d(in_channels)\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x, skip_connection):\n        \n        # Apply padding\n        x = self.conv_transpose(x)\n        x = torch.cat([x, skip_connection], dim=1)\n        if self.normalisation:\n            x = self.batch_norm(x)\n            \n        x = self.dropout(x)\n        x = self.conv_block(x)\n        return x\n    \n\nclass UNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(UNet, self).__init__()\n        self.encoder1 = EncoderBlock(in_channels, 64)\n        self.encoder2 = EncoderBlock(64, 128)\n        self.encoder3 = EncoderBlock(128, 256, normalization=False)\n        self.encoder4 = EncoderBlock(256, 512, normalization=False)\n        self.bottleneck = Bottleneck(512, 1024)\n        self.decoder1 = DecoderBlock(1024, 512, normalization=False)\n        self.decoder2 = DecoderBlock(512, 256, normalization=False)\n        self.decoder3 = DecoderBlock(256, 128)\n        self.decoder4 = DecoderBlock(128, 64)\n        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        enc1, conv1 = self.encoder1(x)\n        enc2, conv2 = self.encoder2(enc1)\n        enc3, conv3 = self.encoder3(enc2)\n        enc4, conv4 = self.encoder4(enc3)\n        bottleneck = self.bottleneck(enc4)\n        dec1 = self.decoder1(bottleneck, conv4)\n        dec2 = self.decoder2(dec1, conv3)\n        dec3 = self.decoder3(dec2, conv2)\n        dec4 = self.decoder4(dec3, conv1)\n        output = self.output(dec4)\n#         output = nn.functional.sigmoid(output)\n        return output\n\n\n\ndef rle_encode(mask):\n    \"\"\"\n    rle encoder (thanks to the community)\n    \"\"\"\n    pixel = mask.flatten()\n    pixel[pixel<0.5] = 0\n    pixel[pixel>=0.5] = 1 \n    pixel = np.concatenate([[0], pixel, [0]])\n    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n    run[1::2] -= run[::2]\n    rle = ' '.join(str(r) for r in run)\n    if rle == '':\n        rle = '1 1'\n    return rle","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:02.181069Z","iopub.execute_input":"2024-04-28T16:13:02.181543Z","iopub.status.idle":"2024-04-28T16:13:02.205842Z","shell.execute_reply.started":"2024-04-28T16:13:02.181505Z","shell.execute_reply":"2024-04-28T16:13:02.204865Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import re\n# def rename_keys(state_dict, prefix):\n#     return {k[len(prefix):]: v for k, v in state_dict.items() if k.startswith(prefix)}\n\ndef rename_keys(original_dict, pattern):\n    new_dict = {}\n    \n    for old_key, value in original_dict.items():\n        new_key = re.sub(pattern, '', old_key)\n        \n        new_dict[new_key] = value\n    \n    return new_dict\n\n# Load state dictionary from checkpoint\nupdated_state_dict = rename_keys(torch.load(WEIGHTS_PATH, map_location=\"cpu\")[\"state_dict\"], \"net.\")\n\nmodel = UNet(INPUT_CHANNELS, OUTPUT_CHANNELS)\nmodel.load_state_dict(updated_state_dict)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:02.484188Z","iopub.execute_input":"2024-04-28T16:13:02.484883Z","iopub.status.idle":"2024-04-28T16:13:08.870977Z","shell.execute_reply.started":"2024-04-28T16:13:02.484852Z","shell.execute_reply":"2024-04-28T16:13:08.870066Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"UNet(\n  (encoder1): EncoderBlock(\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (encoder2): EncoderBlock(\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (encoder3): EncoderBlock(\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (encoder4): EncoderBlock(\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (bottleneck): Bottleneck(\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n  )\n  (decoder1): DecoderBlock(\n    (conv_transpose): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (batch_norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder2): DecoderBlock(\n    (conv_transpose): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder3): DecoderBlock(\n    (conv_transpose): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder4): DecoderBlock(\n    (conv_transpose): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (conv_block): Conv2dBlock(\n      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU()\n    )\n    (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (output): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"rles, ids = [], []\ndatasets = sorted(glob(f\"{MAIN_PATH}/test/*\"))\ninferer = SlidingWindowInferer(mode='gaussian', roi_size=(512,512))\n\nfor dataset in datasets:\n    test_dataset = BuildDataset(dataset, is_test=True)\n\n    input_tensor = torch.from_numpy(test_dataset.normilize(test_dataset.data_tensor)).unsqueeze(1)\n\n    model.eval()\n    with torch.no_grad():\n        ids += test_dataset.ids\n        for tensor in input_tensor:\n            tensor = tensor.float().unsqueeze(0).to(device)\n            output = inferer(inputs=tensor, network=model)\n\n            rle_output = rle_encode(output.cpu())\n            rles.append(rle_output)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:08.872684Z","iopub.execute_input":"2024-04-28T16:13:08.872959Z","iopub.status.idle":"2024-04-28T16:13:13.490330Z","shell.execute_reply.started":"2024-04-28T16:13:08.872936Z","shell.execute_reply":"2024-04-28T16:13:13.489321Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 24624.09it/s]\n100%|██████████| 3/3 [00:00<00:00, 17.32it/s]\n100%|██████████| 3/3 [00:00<00:00, 19878.22it/s]\n100%|██████████| 3/3 [00:00<00:00, 21.63it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(rles, columns=['rle'], index=ids)\n\n# Save DataFrame to a CSV file\nsubmission.to_csv('submission.csv', index_label='id', columns=['rle'])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:13.491779Z","iopub.execute_input":"2024-04-28T16:13:13.492316Z","iopub.status.idle":"2024-04-28T16:13:13.507417Z","shell.execute_reply.started":"2024-04-28T16:13:13.492288Z","shell.execute_reply":"2024-04-28T16:13:13.506505Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:13:16.588537Z","iopub.execute_input":"2024-04-28T16:13:16.589435Z","iopub.status.idle":"2024-04-28T16:13:16.601473Z","shell.execute_reply.started":"2024-04-28T16:13:16.589396Z","shell.execute_reply":"2024-04-28T16:13:16.600575Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"               rle\nkidney_5_0000  1 1\nkidney_5_0001  1 1\nkidney_5_0002  1 1\nkidney_6_0000  1 1\nkidney_6_0001  1 1\nkidney_6_0002  1 1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>kidney_5_0000</th>\n      <td>1 1</td>\n    </tr>\n    <tr>\n      <th>kidney_5_0001</th>\n      <td>1 1</td>\n    </tr>\n    <tr>\n      <th>kidney_5_0002</th>\n      <td>1 1</td>\n    </tr>\n    <tr>\n      <th>kidney_6_0000</th>\n      <td>1 1</td>\n    </tr>\n    <tr>\n      <th>kidney_6_0001</th>\n      <td>1 1</td>\n    </tr>\n    <tr>\n      <th>kidney_6_0002</th>\n      <td>1 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}